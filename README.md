# AplacChat

The HTML parser reads the input files and generates output files. Both input/output files are meant to be existing on the same running machine. This component runs on the following environment.
Windows

# HTML Parser
HTML Parser is used to parse Japanese sentenses in HTML files and emit files that are the input dataset for NMT training. The dataset files that are generated by HTML Parser are:
* Training source (*.src)
* Training target (*.tgt)
* Vocaburary (vocab.src)

The HTML files, that are fed into HTML Parser, are downloaded from APLaC site and saved locally as HTML (*.html) files. 

## Setup Environment (Windows + Python 3)
HTML Parser is develped on Windows + Python 3 and currently (as of Dec.2017) it runs on Windows only. Mac/Unit is supposed to be eligible, but due to the difference of Python version and the default file encoding type (UTF, ECU etc, too complicated. Plus, the HTML files downloaded from APLaC site is all in Shift-JIS), it ended up in sticking to Windows environment.

### Things required in advance
* Python 3.5
* pip

### Things to be installed
* chardet
```
pip install chardet
```
* Beautiful Soup 4
```
pip install beautifulsoup4
```
### Check Installation and Test
Run the unit tests and see if they run all OK.
```
C:\prg\aplac\HTMLParser>python RunTest.py
.........
----------------------------------------------------------------------
Ran 9 tests in 0.006s

OK
```

## How to Run
### 1. Download HTML Files
Get the files from the web site which is to be input of NMT and save them in your local folder. The folder structure can be nested. All existing HTML files are searched under the root folder.
### 2. Configuration
Currently (as of Dec.2017), you need to specify the input file location within the code. Look into a file HTMLParser\run_parse.py and modify the line below.
```
html_folder = "C:\\Tmp\\aplac\\html"
```
### 3. Run
Execute the python file run_parse.py.
```
python run_parse.py
```
The result is generated within a folder 'export' under the same path of the python file.

# NMT Training/Inference
## Setup Environment (MacOS + Python 2)
Python 2 is used because Google Cloud Machine Learning Engine doesn't support Python3 as of Dec.2017. Also Tensorflow version 1.2.0 is required because Google Cloud Platform doesn't support 1.4 as of Dec.2017.
This environment is for both development and actual use of APLaC Chat training and inference. Follow the steps below to setup.

### Things required in advance
* Tensorflow only supports Mac OS 10.11.
* easy_install (this is the Apple's pre-installed version of Python)

### Things to be installed
* pip
* virtualenv
* Tensorflow 1.2.0
* Google Cloud SDK

### Installing Tensorflow
#### 1. Install pip
```
$ sudo easy_install pip
```
If easy_install doesn't work with error like "Could not find suitable distribution for Requirement.parse('pip')", go to https://www.python.org/downloads/mac-osx/ and download the recent build of Python2, run the installer.

#### 2. Install virtualenv
```
$ pip install --upgrade virtualenv
```
#### 3. Create virtualenv environment
```
$ virtualenv --system-site-packages ~/prg/virtualenv/tf120p2
```
#### 4. Activate the environment
Create an alias that activates the virtual environment. Open ~/.bash_profile and add the following line.
```
alias activate_tf120p2="source /Users/ryuji/prg/virtualenv/tf120p2/bin/activate"
```
Then re-open the terminal to refresh. Then type the command to activate the environment.
```
$ activate_tf120p2
```
#### 5. Install tensorflow (CPU version) into virtualenv
Download the wheel file from https://pypi.python.org/pypi/tensorflow/1.2.0, save the file locally, and run the pip command below.
```
$ pip install --upgrade ~/prg/tensorflow/tensorflow-1.2.0-cp27-cp27m-macosx_10_11_x86_64.whl
```
#### Check
Check if Tensorflow is successfully installed.
```
(tensorflow)C:> Python
>>> import tensorflow as tf
>>> print (tf.__version__)
```
Check what packages are installed.
```
$ pip list --local
```

### Installing Google Cloud SDK
Google Cloud SDK is required to access to Google Cloud Platform (GCP). In our project, GCP is used to train and infer in both locally and remotelly (on cloud).
#### Download SDK
The installation is done by downloading the archive file and place its extract. For now it's placed under:
```
~/prg/tensorflow/google-cloud-sdk
```
#### Set PATH
The SDK doesn't install itself but setting its PATH is required.
Edit the virtualenv's activate file by appending the following line. By doing this, Google Cloud SDK becomes available when the virtual environment is activated.
The file edited:
```
~/prg/virtualenv/tf120p2/bin/activate
```
The line added:
```
export PATH=/Users/ryuji/prg/tensorflow/google-cloud-sdk/bin:$PATH
```

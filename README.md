# AplacChat

AplacChat is a deep learning project that focuses on Neural Machine Translation (NMT). The final outcome is [here](http://aplac-chat.koni4.net/).
AplacChat consists of the following components.
* HTML Parser
* Chat
* Front-End Web Page

## Running Environment
* Python 2 for MacOS
* Python 3 for Windows
* Tensorflow 1.4
* Google Cloud Platform used for NMT Training
* Amazon Web Service used for NMT Inference back-end
* Microsoft Azure used for front-end web page

## Corpus Builder
Corpus Builder is used to generate the NMT dataset that include train, dev, test and vocaburary files from various source of text data. The NMT dataset files that are generated by Corpus Builder are:
* Training source (*.src)
* Training target (*.tgt)
* Vocaburary (vocab.src)

Corpus Builder can export text data from a banch of HTML files. For the AplacChat project, the HTML files are downloaded from [APLaC site](https://aplac.net/) and saved locally as HTML (*.html) files, as permission observed by the site author Mr.Tamura.

[Corpus Builder](CorpusBuilder/README.md)

## Chat
Chat is the component that plays the main role of the AplacChat project that is NMT Training and Inference. The running environment of this component changes depending on the project phases and the usage of this component.

### Local Development
When the project is in the development phase and you test run it locally, your local computer (MacOS X) is used. Here both NMT Training and Inference are your main subject.

[How to setup Chat on MacOS](chat/README%20Setup%20Chat%20on%20MacOS.md)

### NMT Training
The project phase moves on, when you want to train Chat, Google Cloud Platform (GCP) is used. This is the case where you want to run training intensively but your local machine is not sufficient as a resource, and thus you need a more powerful machine. You upload the Chat component to GCP and it runs on there.

[How to setup Chat on GCP](chat/README%20Setup%20chat%20on%20GCP.md)

### NMT Inference
The final phase is inference. In this phase you run the Chat component on the production Linux server.

The Chat component can be separatelly setup, but here we set it up together with the Front-End component on the same Linux instance on Amazon Web Service (AWS). Follow the steps in [How to setup Chat/Frontend on AWS EC2](frontend/README%20Setup%20chat-frontend%20on%20AWS%20EC2.md).

## Front-End Web Page
Front-End is a web page that accepts the text the user types in, sends the text to the Chat component and shows the translation that is the result of NMT Inference.

To start a local debugging on your Mac with Visual Studio Code, read [How to setup Front-End on MacOS](frontend/README%20Setup%20frontend%20on%20MacOS.md). To deploy on to AWS EC2 Linux instance, refer to [How to setup Chat/Frontend on AWS EC2](frontend/README%20Setup%20chat-frontend%20on%20AWS%20EC2.md).
